{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import argparse, json, copy, os\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from deep_dialog.dialog_system import DialogManager, text_to_dict\n",
    "from deep_dialog.agents import AgentCmd, InformAgent, RequestAllAgent, RandomAgent, EchoAgent, RequestBasicsAgent, AgentDQN\n",
    "from deep_dialog.usersims import RuleSimulator\n",
    "\n",
    "from deep_dialog import dialog_config\n",
    "from deep_dialog.dialog_config import *\n",
    "\n",
    "from deep_dialog.nlu import nlu\n",
    "from deep_dialog.nlg import nlg\n",
    "from deep_dialog.nlg.lstm_decoder_tanh import lstm_decoder_tanh\n",
    "from IPython import *\n",
    "from notebook_util import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_nlg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlg_model_path = './deep_dialog/models/nlg/lstm_tanh_relu_[1468202263.38]_2_0.610.p'\n",
    "nlg_model = nlg()\n",
    "nlg_model.load_nlg_model(nlg_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>model_params Keys:</h4> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = pickle.load(open(nlg_model_path, 'rb'), encoding='latin1')\n",
    "display.HTML('<h4>{}</h4> '.format(\"model_params Keys:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act_dict',\n",
       " 'template_word_dict',\n",
       " 'epochs',\n",
       " 'word_dict',\n",
       " 'params',\n",
       " 'slot_dict',\n",
       " 'model',\n",
       " 'slot_val_dict']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### acttions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'closing': 5,\n",
       " 'confirm_answer': 3,\n",
       " 'confirm_question': 2,\n",
       " 'deny': 9,\n",
       " 'greeting': 4,\n",
       " 'inform': 1,\n",
       " 'multiple_choice': 6,\n",
       " 'not_sure': 10,\n",
       " 'request': 0,\n",
       " 'thanks': 7,\n",
       " 'welcome': 8}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params['act_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word dict: keys = 1527\n",
      "Sample of word dict:\n",
      "[('21', 829), ('ness', 1149), ('97232', 458), ('7:55pm', 1392), ('lansing', 1120), ('come', 536)]\n"
     ]
    }
   ],
   "source": [
    "word_dict=model_params['word_dict']\n",
    "keys = word_dict.keys()\n",
    "print(\"word dict: keys = {}\".format(len(keys)))\n",
    "print(\"Sample of word dict:\")\n",
    "random_keys = np.random.choice(list(keys), 6)\n",
    "print([(k, word_dict[k]) for k in random_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template word dict: keys = 1047\n",
      "Sample of word dict:\n",
      "[('shall', 508), (\"i'm\", 95), ('across', 557), ('7038', 414), ('gotten', 265)]\n"
     ]
    }
   ],
   "source": [
    "template_word_dict = model_params['template_word_dict']\n",
    "keys = template_word_dict.keys()\n",
    "print(\"template word dict: keys = {}\".format(len(keys)))\n",
    "print(\"Sample of word dict:\")\n",
    "random_keys = np.random.choice(list(keys), 5)\n",
    "print([(k, template_word_dict[k]) for k in random_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params['epochs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1148, 400)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params['model']['WLSTM'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116, 400)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params['model']['Wah'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1047)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params['model']['Wd'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 400)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params['model']['bah'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1047)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params['model']['bd'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 100\n"
     ]
    }
   ],
   "source": [
    "hidden_size = model_params['model']['Wd'].shape[0]\n",
    "print(\"hidden_size: {}\".format(hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_size: 1047\n"
     ]
    }
   ],
   "source": [
    "output_size = model_params['model']['Wd'].shape[1]\n",
    "print(\"output_size: {}\".format(output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Tanh\n",
      "diaact_input_size = 1116\n",
      "input_size = 1047\n"
     ]
    }
   ],
   "source": [
    "if model_params['params']['model'] == 'lstm_tanh': # lstm_tanh\n",
    "        print(\"LSTM_Tanh\")\n",
    "        diaact_input_size = model_params['model']['Wah'].shape[0]\n",
    "        input_size = model_params['model']['WLSTM'].shape[0] - hidden_size - 1\n",
    "        rnnmodel = lstm_decoder_tanh(diaact_input_size, input_size, hidden_size, output_size)\n",
    "        print(\"diaact_input_size = {}\".format(diaact_input_size))\n",
    "        print(\"input_size = {}\".format(input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
